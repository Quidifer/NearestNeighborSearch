{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-0.084975892, 1.4136573, 0.95165009, -0.6215477, -0.19397639, 0.19818832], 2.0)\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "input_file = \"CS170_Small_Data__96.txt\"\n",
    "\n",
    "input_data: list[(list[float], int)] = []\n",
    "FEATURES = 0\n",
    "CLASS = 1\n",
    "\n",
    "def import_data(file: str):\n",
    "    input_data.clear()\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            f_list = [float(i) for i in line.split(\" \") if i.strip()]\n",
    "            input_data.append((f_list[1:], f_list[0]))\n",
    "\n",
    "import_data(input_file)\n",
    "print(input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example euclidean distance:  1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#Euclidean distance\n",
    "#p1 and p2 must have the same dimensionality\n",
    "def dist(p1: list[float], p2: list[float]) -> float:\n",
    "    sum = 0\n",
    "    for i in range(len(p1)):\n",
    "        sum += math.pow(p1[i] - p2[i], 2)\n",
    "    return math.sqrt(sum)\n",
    "\n",
    "print(\"example euclidean distance: \", dist([1.0, 2.0], [2.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example classification:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I will use this hardcoded K value\n",
    "K = 7\n",
    "\n",
    "#K nearest neighbors\n",
    "# returns the Classification (1 or 2)\n",
    "def KNN(p: list[float], data: list[(list[float], int)], k: int) -> int:\n",
    "    d: list[(float, int)] = []\n",
    "    for i, tuple in enumerate(data):\n",
    "        d.append((dist(p, tuple[FEATURES]), tuple[CLASS]))\n",
    "    d.sort()\n",
    "    d = d[:k]\n",
    "\n",
    "    # this part is hard coded to the data:\n",
    "    # classes are 1 and 2\n",
    "    a = 0\n",
    "    b = 0\n",
    "    for i, item in enumerate(d):\n",
    "        if item[CLASS] == 1:\n",
    "            a += 1\n",
    "        else:\n",
    "            b += 1\n",
    "\n",
    "    if a > b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "print(\"example classification:\")\n",
    "KNN(input_data[0][FEATURES], input_data[1:], K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test classification using all points\n",
      "0.86\n",
      "Test classification using features 1, 3, and 6\n",
      "0.94\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "#classify\n",
    "def classify8020(data: list[(list[float], int)]):\n",
    "    split = int(len(data) * 0.2)\n",
    "    test = data[:split]\n",
    "    train = data[split:]\n",
    "\n",
    "    num_correct = 0\n",
    "    for i, tuple in enumerate(test):\n",
    "        classification = KNN(tuple[FEATURES], train, K)\n",
    "        if classification == tuple[CLASS]:\n",
    "            num_correct += 1\n",
    "    \n",
    "    return num_correct / len(test)\n",
    "\n",
    "def classify(data: list[(list[float], int)]):\n",
    "    total = 0\n",
    "    num_correct = 0\n",
    "    for i, tuple in enumerate(data):\n",
    "        train = copy.copy(data)\n",
    "        del train[i]\n",
    "\n",
    "        classification = KNN(tuple[FEATURES], train, K)\n",
    "        \n",
    "        if classification == tuple[CLASS]:\n",
    "            num_correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    return num_correct / total\n",
    "\n",
    "#construct data given feature the numbers\n",
    "def construct_data(features: list[float], data: list[(list[float], int)]) -> list[float]:\n",
    "    my_data = []\n",
    "    for i, tuple in enumerate(data):\n",
    "        temp = []\n",
    "        for feature in features:\n",
    "            temp.append(tuple[FEATURES][feature-1])\n",
    "        my_data.append((temp, tuple[CLASS]))\n",
    "    return my_data\n",
    "\n",
    "print(\"Test classification using all points\")\n",
    "print(classify(input_data))\n",
    "\n",
    "print(\"Test classification using features 1, 3, and 6\")\n",
    "print(classify(construct_data([1,3,6], input_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing feature(s):  [1]  accuracy:  0.868\n",
      "testing feature(s):  [2]  accuracy:  0.804\n",
      "testing feature(s):  [3]  accuracy:  0.81\n",
      "testing feature(s):  [4]  accuracy:  0.798\n",
      "testing feature(s):  [5]  accuracy:  0.794\n",
      "testing feature(s):  [6]  accuracy:  0.768\n",
      "\n",
      " Best feature was  [1]  accuracy:  0.868 \n",
      "\n",
      "testing feature(s):  [1, 2]  accuracy:  0.81\n",
      "testing feature(s):  [1, 3]  accuracy:  0.894\n",
      "testing feature(s):  [1, 4]  accuracy:  0.85\n",
      "testing feature(s):  [1, 5]  accuracy:  0.84\n",
      "testing feature(s):  [1, 6]  accuracy:  0.964\n",
      "\n",
      " Best feature was  [1, 6]  accuracy:  0.964 \n",
      "\n",
      "testing feature(s):  [1, 6, 2]  accuracy:  0.926\n",
      "testing feature(s):  [1, 6, 3]  accuracy:  0.94\n",
      "testing feature(s):  [1, 6, 4]  accuracy:  0.936\n",
      "testing feature(s):  [1, 6, 5]  accuracy:  0.922\n",
      "\n",
      " Best feature was  [1, 6, 3]  accuracy:  0.94 \n",
      "\n",
      "testing feature(s):  [1, 6, 3, 2]  accuracy:  0.9\n",
      "testing feature(s):  [1, 6, 3, 4]  accuracy:  0.902\n",
      "testing feature(s):  [1, 6, 3, 5]  accuracy:  0.898\n",
      "\n",
      " Best feature was  [1, 6, 3, 4]  accuracy:  0.902 \n",
      "\n",
      "testing feature(s):  [1, 6, 3, 4, 2]  accuracy:  0.88\n",
      "testing feature(s):  [1, 6, 3, 4, 5]  accuracy:  0.876\n",
      "\n",
      " Best feature was  [1, 6, 3, 4, 2]  accuracy:  0.88 \n",
      "\n",
      "testing feature(s):  [1, 6, 3, 4, 2, 5]  accuracy:  0.86\n",
      "\n",
      " Best feature was  [1, 6, 3, 4, 2, 5]  accuracy:  0.86 \n",
      "\n",
      "Finished... The best feature set was [1, 6] with an accuracy of 0.964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1, 6], 0.964)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def forward_selection(DEBUG: bool = False):\n",
    "    best_ever = 0\n",
    "    best_set_ever = []\n",
    "    best_so_far = []\n",
    "    for i in range(len(input_data[0][FEATURES])):\n",
    "        #keeps track of best accuracy for this group\n",
    "        best = 0.0\n",
    "        for j in range(len(input_data[0][FEATURES])):\n",
    "            #check to see if this feature exists in this feature set yet\n",
    "            if j+1 in best_so_far:\n",
    "                continue\n",
    "\n",
    "            #copy over and add a new feature\n",
    "            feature_set = copy.copy(best_so_far[:i])\n",
    "            feature_set.append(j+1)\n",
    "            \n",
    "            data = construct_data(feature_set, input_data)\n",
    "            accuracy = classify(data)\n",
    "\n",
    "            if DEBUG:\n",
    "                print(\"testing feature(s): \", feature_set, \" accuracy: \", accuracy)\n",
    "            \n",
    "            \n",
    "            # check if this set was better than any others in its group\n",
    "            if accuracy > best:\n",
    "                best = accuracy\n",
    "                best_so_far = feature_set\n",
    "            # check if this set was better than any other set ever\n",
    "            if accuracy > best_ever:\n",
    "                best_ever = accuracy\n",
    "                best_set_ever = feature_set\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"\\n Best feature was \", best_so_far, \" accuracy: \", best, \"\\n\")\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"Finished... The best feature set was\", best_set_ever, \"with an accuracy of\", best_ever)\n",
    "\n",
    "    return (best_set_ever, best_ever)\n",
    "\n",
    "forward_selection(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing feature(s):  [1, 2, 3, 4, 5, 6]  accuracy:  0.86\n",
      "\n",
      " Best feature was  [1, 2, 3, 4, 5, 6]  accuracy:  0.86 \n",
      "\n",
      "testing feature(s):  [2, 3, 4, 5, 6]  accuracy:  0.79\n",
      "testing feature(s):  [1, 3, 4, 5, 6]  accuracy:  0.876\n",
      "testing feature(s):  [1, 2, 4, 5, 6]  accuracy:  0.854\n",
      "testing feature(s):  [1, 2, 3, 5, 6]  accuracy:  0.86\n",
      "testing feature(s):  [1, 2, 3, 4, 6]  accuracy:  0.88\n",
      "testing feature(s):  [1, 2, 3, 4, 5]  accuracy:  0.832\n",
      "\n",
      " Best feature was  [1, 2, 3, 4, 6]  accuracy:  0.88 \n",
      "\n",
      "testing feature(s):  [2, 3, 4, 6]  accuracy:  0.782\n",
      "testing feature(s):  [1, 3, 4, 6]  accuracy:  0.902\n",
      "testing feature(s):  [1, 2, 4, 6]  accuracy:  0.876\n",
      "testing feature(s):  [1, 2, 3, 6]  accuracy:  0.9\n",
      "testing feature(s):  [1, 2, 3, 4]  accuracy:  0.842\n",
      "\n",
      " Best feature was  [1, 3, 4, 6]  accuracy:  0.902 \n",
      "\n",
      "testing feature(s):  [3, 4, 6]  accuracy:  0.796\n",
      "testing feature(s):  [1, 4, 6]  accuracy:  0.936\n",
      "testing feature(s):  [1, 3, 6]  accuracy:  0.94\n",
      "testing feature(s):  [1, 3, 4]  accuracy:  0.852\n",
      "\n",
      " Best feature was  [1, 3, 6]  accuracy:  0.94 \n",
      "\n",
      "testing feature(s):  [3, 6]  accuracy:  0.806\n",
      "testing feature(s):  [1, 6]  accuracy:  0.964\n",
      "testing feature(s):  [1, 3]  accuracy:  0.894\n",
      "\n",
      " Best feature was  [1, 6]  accuracy:  0.964 \n",
      "\n",
      "testing feature(s):  [6]  accuracy:  0.768\n",
      "testing feature(s):  [1]  accuracy:  0.868\n",
      "\n",
      " Best feature was  [1]  accuracy:  0.868 \n",
      "\n",
      "Finished... The best feature set was [1, 6] with an accuracy of 0.964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1, 6], 0.964)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backward_selection(DEBUG:bool = False):\n",
    "    #best ever accuracy\n",
    "    best_ever = classify(input_data)\n",
    "\n",
    "    #best set ever\n",
    "    best_set_ever = list(range(1, len(input_data[0][FEATURES])+1))\n",
    "\n",
    "    #best set\n",
    "    best_so_far = best_set_ever\n",
    "\n",
    "    #initial\n",
    "    if DEBUG:\n",
    "        print(\"testing feature(s): \", best_so_far, \" accuracy: \", best_ever)\n",
    "        print(\"\\n Best feature was \", best_so_far, \" accuracy: \", best_ever, \"\\n\")\n",
    "\n",
    "    for i in range(len(input_data[0][FEATURES])-1):\n",
    "        best = 0.0\n",
    "        curr = best_so_far\n",
    "        for j in curr:\n",
    "            #test a new feature set by removing a feature\n",
    "            feature_set = copy.copy(curr)\n",
    "            feature_set.remove(j)\n",
    "            \n",
    "            data = construct_data(feature_set, input_data)\n",
    "            accuracy = classify(data)\n",
    "            if DEBUG:\n",
    "                print(\"testing feature(s): \", feature_set, \" accuracy: \", accuracy)\n",
    "\n",
    "            # check if this set was better than any others in its group\n",
    "            if accuracy > best:\n",
    "                best = accuracy\n",
    "                best_so_far = feature_set\n",
    "            # check if this set was better than any other set ever\n",
    "            if accuracy > best_ever:\n",
    "                best_ever = accuracy\n",
    "                best_set_ever = feature_set\n",
    "\n",
    "        if DEBUG:\n",
    "            print(\"\\n Best feature was \", best_so_far, \" accuracy: \", best, \"\\n\")\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"Finished... The best feature set was\", best_set_ever, \"with an accuracy of\", best_ever)\n",
    "    \n",
    "    return (best_set_ever, best_ever)\n",
    "\n",
    "backward_selection(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test classification using features 37, 36, and 40\n",
      "0.959\n",
      "Test classification using features 2, 5, 3\n",
      "0.918\n",
      "Test classification using features 21,8,10\n",
      "0.953\n",
      "Test classification using features 5,2,1\n",
      "0.94\n",
      "Test classification using features 22,1,6\n",
      "0.956\n"
     ]
    }
   ],
   "source": [
    "#expect 0.947\n",
    "import_data(\"CS170_Large_Data__21.txt\")\n",
    "print(\"Test classification using features 37, 36, and 40\")\n",
    "print(classify(construct_data([37,36,40], input_data)))\n",
    "\n",
    "#expect 0.916\n",
    "import_data(\"CS170_Small_Data__6.txt\")\n",
    "print(\"Test classification using features 2, 5, 3\")\n",
    "print(classify(construct_data([2,5,3], input_data)))\n",
    "\n",
    "#expect 0.947\n",
    "import_data(\"CS170_Large_Data__96.txt\")\n",
    "print(\"Test classification using features 21,8,10\")\n",
    "print(classify(construct_data([21,8,10], input_data)))\n",
    "\n",
    "#expect 0.936\n",
    "import_data(\"CS170_Small_Data__88.txt\")\n",
    "print(\"Test classification using features 5,2,1\")\n",
    "print(classify(construct_data([5,2,1], input_data)))\n",
    "\n",
    "#expect 0.954\n",
    "import_data(\"CS170_Large_Data__6.txt\")\n",
    "print(\"Test classification using features 22,1,6\")\n",
    "print(classify(construct_data([22,1,6], input_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test classification using features 2, 5, 3\n",
      "0.918\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa82987a71ca0339a52998cd22613b0c002bda8349fa32a0cb67ceec3936a2bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
